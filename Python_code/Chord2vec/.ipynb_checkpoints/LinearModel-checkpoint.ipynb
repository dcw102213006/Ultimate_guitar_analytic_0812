{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import sys\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "Linear model implementation in tensorflow\n",
    "'''\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from chord2vec.linear_models import data_processing as dp\n",
    "import numpy as np\n",
    "import random\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "import time\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會把資料整理成train_chords、test_chords、valid_chords三個lists <br>\n",
    "整理過的話直接跳到 \n",
    "# 儲存train_chords、test_chords、valid_chords\n",
    "此chunk，以製作train_set來練chord_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_train_merged=pd.read_csv('../../data/song_train_merged_transferkey0425.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>chord</th>\n",
       "      <th>error</th>\n",
       "      <th>rating</th>\n",
       "      <th>tab_href</th>\n",
       "      <th>tab_title</th>\n",
       "      <th>version</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_detector_chord</th>\n",
       "      <th>song_chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5cada0049fc5af34a460ae05</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/art_...</td>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Art For Arts Sake 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...</td>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5cada0049fc5af34a460ae07</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/baro...</td>\n",
       "      <td>Baron Samedi</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Baron Samedi 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...</td>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1                       _id artist  \\\n",
       "0           0             0              28  5cada0049fc5af34a460ae05   10cc   \n",
       "1           1             1              29  5cada0049fc5af34a460ae07   10cc   \n",
       "\n",
       "                                               chord  error rating  \\\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...      0      9   \n",
       "1  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...      0      3   \n",
       "\n",
       "                                            tab_href          tab_title  \\\n",
       "0  https://tabs.ultimate-guitar.com/tab/10cc/art_...  Art For Arts Sake   \n",
       "1  https://tabs.ultimate-guitar.com/tab/10cc/baro...       Baron Samedi   \n",
       "\n",
       "  version               song_name  \\\n",
       "0   Ver 1  Art For Arts Sake 10cc   \n",
       "1   Ver 1       Baron Samedi 10cc   \n",
       "\n",
       "                                 song_detector_chord  \\\n",
       "0  [{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...   \n",
       "1  [{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...   \n",
       "\n",
       "                                          song_chord  \n",
       "0  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...  \n",
       "1  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=song_train_merged.copy()\n",
    "df['song_chord']=df['song_chord'].apply(literal_eval)\n",
    "df['chord']=df['chord'].apply(literal_eval)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A:maj',\n",
       " 'A:min',\n",
       " 'Ab:maj',\n",
       " 'Ab:min',\n",
       " 'B:maj',\n",
       " 'Bb:maj',\n",
       " 'Bb:min',\n",
       " 'C:maj',\n",
       " 'D:maj',\n",
       " 'Db:maj',\n",
       " 'Db:min',\n",
       " 'E:maj',\n",
       " 'E:min',\n",
       " 'Eb:maj',\n",
       " 'Eb:min',\n",
       " 'F:maj',\n",
       " 'F:min',\n",
       " 'G:maj',\n",
       " 'Gb:maj',\n",
       " 'Gb:min',\n",
       " 'N'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#資料集中的所有和絃類別\n",
    "chord_list=[]\n",
    "for row in df.chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "for row in df.song_chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "chord_list=set(chord_list)\n",
    "chord_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec:\n",
    "1.準備好train_data，每一個元素是一個和弦，記錄其onset的index <br>\n",
    "例:以12-vector 做many-hot-encoding，C和弦onset的位置為1,5,8 <br>\n",
    "2.把df的chord(row是每篇吉他譜和弦)欄位與song_chord(吉他譜對應的歌曲做完和弦辨識的欄位)合併成一個欄位<br>\n",
    "以便切train、test、valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用chord2vec_df這張大df切train、test、valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chord\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...\n",
       "1  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...\n",
       "2  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...\n",
       "3  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...\n",
       "4  [Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord2vec_df=df[['chord','song_chord']].stack().reset_index()\n",
    "chord2vec_df[0]\n",
    "chord2vec_df=pd.DataFrame({'chord':chord2vec_df[0]})\n",
    "chord2vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 28142\n",
      "test: 6031\n",
      "valid: 6031\n"
     ]
    }
   ],
   "source": [
    "chord2vec_df_train, chord2vec_df_test = train_test_split(chord2vec_df, test_size=0.3, random_state=2019)\n",
    "chord2vec_df_test,chord2vec_df_valid=train_test_split(chord2vec_df_test, test_size=0.5, random_state=2019)\n",
    "\n",
    "print('train:',len(chord2vec_df_train))\n",
    "print('test:',len(chord2vec_df_test))\n",
    "print('valid:',len(chord2vec_df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chord_word_data:list,存吉他譜與歌曲的和弦進行，一個和弦是一個字，一首歌曲譜是一篇文章\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "valid_data=[]\n",
    "for row in chord2vec_df_train.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    train_data.append(row_list)\n",
    "for row in chord2vec_df_test.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    test_data.append(row_list)\n",
    "for row in chord2vec_df_valid.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    valid_data.append(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec需要每個字(和弦)的上下文序列作為訓練資料 \n",
    "使用dp.make_chord_context(train_data,test_data,valid_data,1)幫和弦配對上下文 <br>\n",
    "使用prepare_training_data(train_chords,test_chords,valid_chords)把train_set，test_set,valid_set做好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.38114953041077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#需要1~2分鐘\n",
    "start = time.time()\n",
    "train_chords, test_chords , valid_chords = dp.make_chord_context(train_data,test_data,valid_data,1)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#沒用到的變數先刪掉  節省記憶體\n",
    "del chord2vec_df_train,chord2vec_df_test,chord2vec_df_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord2vec_df,df,row,row_list,song_train_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del   train_data,test_data,valid_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存train_chords、test_chords、valid_chords\n",
    "train_chords已經做完context配對  <br>\n",
    "接下來要製作train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# out = open(\"LinearModel_data/0513/train_chords.pkl\",\"wb\")\n",
    "# pickle.dump(train_chords, out)\n",
    "# out = open(\"LinearModel_data/0513/test_chords.pkl\",\"wb\")\n",
    "# pickle.dump(test_chords, out)\n",
    "# out = open(\"LinearModel_data/0513/valid_chords.pkl\",\"wb\")\n",
    "# pickle.dump(valid_chords, out)\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('LinearModel_data/0513/train_chords.pkl', 'rb') as pickle_load:\n",
    "    train_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/0513/test_chords.pkl', 'rb') as pickle_load:\n",
    "    test_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/0513/valid_chords.pkl', 'rb') as pickle_load:\n",
    "    valid_chords = pickle.load(pickle_load)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(train_chords,test_chords,valid_chords):\n",
    "    print('Loading data ...')\n",
    " \n",
    "    train_set = dp.generate_binary_vectors(train_chords)\n",
    "    # input_train, target_train = train_set\n",
    "    del  train_chords\n",
    "    gc.collect()\n",
    "    test_set = dp.generate_binary_vectors(test_chords)\n",
    "    del  test_chords\n",
    "    gc.collect()\n",
    "    valid_set = dp.generate_binary_vectors(valid_chords)\n",
    "    del  valid_chords\n",
    "    gc.collect()\n",
    "    # input_valid, target_valid = valid_set\n",
    "    \n",
    "    data_size = len(train_set[0])\n",
    "    data_size_valid = len(valid_set[0])\n",
    "    data_size_te = len(test_set[0])\n",
    "\n",
    "    total_batch = int(data_size / batch_size)\n",
    "    total_batch_valid = int(data_size_valid / batch_size)\n",
    "    total_batch_test = int(data_size_te / batch_size)\n",
    "\n",
    "    return train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "D = 100 # 1st layer number of features\n",
    "NUM_NOTES = 12 #nums of Vocab\n",
    "\n",
    "# tf Graph input\n",
    "input = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "target = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "\n",
    "# Create model\n",
    "def linear(input, weights):\n",
    "    hidden = tf.matmul( \n",
    "        tf.truediv(\n",
    "            input, \n",
    "            tf.maximum(\n",
    "                1.0,\n",
    "                tf.reduce_sum(\n",
    "                    input, \n",
    "                    1, \n",
    "                    keep_dims=True\n",
    "                )\n",
    "            ) \n",
    "        ) ,\n",
    "        weights['hidden']\n",
    "    ) #+ bias['hidden1']\n",
    "    out_layer = tf.matmul(\n",
    "        hidden,\n",
    "        weights['out'])# + bias['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([NUM_NOTES, D]),name='embedding'),\n",
    "    'out': tf.Variable(tf.random_normal([D, NUM_NOTES]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hidden': tf.Variable(tf.random_normal([D])),\n",
    "    'out': tf.Variable(tf.random_normal([NUM_NOTES]))\n",
    "}\n",
    "embedding_initial=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data_set,id, stoch=False):\n",
    "    if stoch:\n",
    "        transpose_data_set = list(map(list, zip(*data_set)))\n",
    "        batch = random.sample(transpose_data_set, batch_size)\n",
    "        batch_input,batch_target = list(map(list, zip(*batch)))\n",
    "        return batch_input,batch_target\n",
    "    batch_id = id + 1\n",
    "    input, target = data_set\n",
    "    return input[(batch_id * batch_size - batch_size):(batch_id * batch_size)], target[(batch_id * batch_size - batch_size):(batch_id * batch_size)]\n",
    "\n",
    "\n",
    "def train(checkpoint_path='save_models/linear/0517/linear_D1024.ckpt',load_model=None,print_train=True, print_test=True):\n",
    "    train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid = prepare_training_data(train_chords,test_chords,valid_chords)\n",
    "    data_size = len(train_set[0])\n",
    "\n",
    "    # Construct model\n",
    "    print('Create model ...')\n",
    "    \n",
    "    pred = linear(input, weights)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=target),1))\n",
    "\n",
    "\n",
    "    #optimizer = tf.train.AdamOptimizer(epsilon=1e-01,learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver(tf.all_variables(),max_to_keep=1)\n",
    "    \n",
    "    input_valid, target_valid = valid_set\n",
    "\n",
    "    # Launch the graph\n",
    "    print('Start training ...')\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # checkpoint = False #tf.train.get_checkpoint_state('save_models/linear')\n",
    "        # if checkpoint and tf.gfile.Exists(checkpoint.model_checkpoint_path):\n",
    "        #     print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        #     saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        #     best_val_loss = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "        \n",
    "        print('初始化tf變數...')\n",
    "        sess.run(init)\n",
    "        best_val_loss = np.inf\n",
    "        embedding_initial=sess.run('embedding:0')\n",
    "        \n",
    "        if  print_test:\n",
    "            # Training cycle\n",
    "            previous_eval_loss = []\n",
    "            best_val_epoch = -1\n",
    "            strikes = 0\n",
    "            print('Start Training cycle...')\n",
    "            for epoch in range(training_epochs):\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(data_size/batch_size)\n",
    "                # Loop over all batches\n",
    "                if epoch %10==0:print('Epoch:',epoch,'total_batch:',total_batch)\n",
    "                    \n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = get_batch(train_set,i)\n",
    "                    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                    _, c, out = sess.run([optimizer, cost, pred], feed_dict={input: batch_x,\n",
    "                                                                 target: batch_y})\n",
    "\n",
    "                    # Compute average loss\n",
    "                    avg_cost += c / total_batch\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%d' % (epoch+1), \"cost=\", \\\n",
    "                        \"{:.9f}\".format(avg_cost))\n",
    "                c_valid = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "                print(\"Valid error %4f\" % (c_valid))\n",
    "                previous_eval_loss.append(c_valid)\n",
    "                improve_valid = previous_eval_loss[-1] < best_val_loss\n",
    "\n",
    "                if improve_valid:\n",
    "                    best_val_loss = previous_eval_loss[-1]\n",
    "                    best_val_epoch = epoch\n",
    "                    # Save checkpoint.\n",
    "                    saver.save(sess, checkpoint_path,global_step=epoch)\n",
    "                else:\n",
    "                    strikes += 1\n",
    "                if strikes > 3:\n",
    "                    break\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "        input_test, target_test = test_set\n",
    "        c_test = sess.run(cost, feed_dict={input: input_test, target: target_test})\n",
    "\n",
    "\n",
    "        print(\"Test error %.9f\" % (c_test))\n",
    "        print(\"Best validation %.9f\" % (best_val_loss))\n",
    "        \n",
    "        print('訓練完成')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Create model ...\n",
      "WARNING:tensorflow:From <ipython-input-5-524191929ab6>:25: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-d773a8c4e884>:39: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "Start training ...\n",
      "初始化tf變數...\n",
      "Start Training cycle...\n",
      "Epoch: 0 total_batch: 39901\n",
      "Epoch: 1 cost= 6.703469722\n",
      "Valid error 6.036582\n",
      "Epoch: 2 cost= 6.026319275\n",
      "Valid error 6.036021\n",
      "Epoch: 3 cost= 6.026303447\n",
      "Valid error 6.036022\n",
      "Epoch: 4 cost= 6.026303242\n",
      "Valid error 6.036023\n",
      "Epoch: 5 cost= 6.026303086\n",
      "Valid error 6.036030\n",
      "Epoch: 6 cost= 6.026302940\n",
      "Valid error 6.036088\n",
      "Epoch: 7 cost= 6.026302787\n",
      "Valid error 6.036122\n",
      "Epoch: 8 cost= 6.026302639\n",
      "Valid error 6.036133\n",
      "Epoch: 9 cost= 6.026302496\n",
      "Valid error 6.036120\n",
      "Epoch: 10 cost= 6.026302333\n",
      "Valid error 6.036078\n",
      "Epoch: 10 total_batch: 39901\n",
      "Epoch: 11 cost= 6.026302205\n",
      "Valid error 6.036030\n",
      "Epoch: 12 cost= 6.026302069\n",
      "Valid error 6.036145\n",
      "Epoch: 13 cost= 6.026301920\n",
      "Valid error 6.036145\n",
      "Epoch: 14 cost= 6.026301767\n",
      "Valid error 6.035884\n",
      "Epoch: 15 cost= 6.026301609\n",
      "Valid error 6.035882\n",
      "Epoch: 16 cost= 6.026301467\n",
      "Valid error 6.035895\n",
      "Epoch: 17 cost= 6.026301331\n",
      "Valid error 6.035945\n",
      "Epoch: 18 cost= 6.026301187\n",
      "Valid error 6.035954\n",
      "Epoch: 19 cost= 6.026301036\n",
      "Valid error 6.035748\n",
      "Epoch: 20 cost= 6.026300881\n",
      "Valid error 6.035922\n",
      "Epoch: 20 total_batch: 39901\n",
      "Epoch: 21 cost= 6.026300726\n",
      "Valid error 6.035946\n",
      "Epoch: 22 cost= 6.026300585\n",
      "Valid error 6.036185\n",
      "Epoch: 23 cost= 6.026300433\n",
      "Valid error 6.036191\n",
      "Epoch: 24 cost= 6.026300287\n",
      "Valid error 6.036168\n",
      "Epoch: 25 cost= 6.026300151\n",
      "Valid error 6.036163\n",
      "Epoch: 26 cost= 6.026299996\n",
      "Valid error 6.036338\n",
      "Epoch: 27 cost= 6.026299854\n",
      "Valid error 6.036318\n",
      "Epoch: 28 cost= 6.026299727\n",
      "Valid error 6.036325\n",
      "Epoch: 29 cost= 6.026299586\n",
      "Valid error 6.036398\n",
      "Epoch: 30 cost= 6.026299438\n",
      "Valid error 6.036368\n",
      "Epoch: 30 total_batch: 39901\n",
      "Epoch: 31 cost= 6.026299307\n",
      "Valid error 6.036330\n",
      "Epoch: 32 cost= 6.026299156\n",
      "Valid error 6.036288\n",
      "Epoch: 33 cost= 6.026299007\n",
      "Valid error 6.036297\n",
      "Epoch: 34 cost= 6.026298849\n",
      "Valid error 6.036328\n",
      "Epoch: 35 cost= 6.026298707\n",
      "Valid error 6.036284\n",
      "Epoch: 36 cost= 6.026298546\n",
      "Valid error 6.036307\n",
      "Epoch: 37 cost= 6.026298416\n",
      "Valid error 6.036208\n",
      "Epoch: 38 cost= 6.026298272\n",
      "Valid error 6.036193\n",
      "Epoch: 39 cost= 6.026298141\n",
      "Valid error 6.036202\n",
      "Epoch: 40 cost= 6.026297999\n",
      "Valid error 6.036568\n",
      "Epoch: 40 total_batch: 39901\n",
      "Epoch: 41 cost= 6.026297833\n",
      "Valid error 6.036548\n",
      "Epoch: 42 cost= 6.026297708\n",
      "Valid error 6.036477\n",
      "Epoch: 43 cost= 6.026297546\n",
      "Valid error 6.036446\n",
      "Epoch: 44 cost= 6.026297415\n",
      "Valid error 6.036461\n",
      "Epoch: 45 cost= 6.026297257\n",
      "Valid error 6.036426\n",
      "Epoch: 46 cost= 6.026297103\n",
      "Valid error 6.036127\n",
      "Epoch: 47 cost= 6.026296960\n",
      "Valid error 6.036114\n",
      "Epoch: 48 cost= 6.026296836\n",
      "Valid error 6.036097\n",
      "Epoch: 49 cost= 6.026296687\n",
      "Valid error 6.036168\n",
      "Epoch: 50 cost= 6.026296526\n",
      "Valid error 6.036036\n",
      "Epoch: 50 total_batch: 39901\n",
      "Epoch: 51 cost= 6.026296391\n",
      "Valid error 6.036139\n",
      "Epoch: 52 cost= 6.026296265\n",
      "Valid error 6.036087\n",
      "Epoch: 53 cost= 6.026296122\n",
      "Valid error 6.036047\n",
      "Epoch: 54 cost= 6.026295985\n",
      "Valid error 6.036056\n",
      "Epoch: 55 cost= 6.026295822\n",
      "Valid error 6.036050\n",
      "Epoch: 56 cost= 6.026295685\n",
      "Valid error 6.036047\n",
      "Epoch: 57 cost= 6.026295537\n",
      "Valid error 6.036191\n",
      "Epoch: 58 cost= 6.026295397\n",
      "Valid error 6.036211\n",
      "Epoch: 59 cost= 6.026295256\n",
      "Valid error 6.036161\n",
      "Epoch: 60 cost= 6.026295107\n",
      "Valid error 6.036170\n",
      "Epoch: 60 total_batch: 39901\n",
      "Epoch: 61 cost= 6.026294991\n",
      "Valid error 6.035819\n",
      "Epoch: 62 cost= 6.026294818\n",
      "Valid error 6.035665\n",
      "Epoch: 63 cost= 6.026294687\n",
      "Valid error 6.035714\n",
      "Epoch: 64 cost= 6.026294550\n",
      "Valid error 6.035695\n",
      "Epoch: 65 cost= 6.026294413\n",
      "Valid error 6.035725\n",
      "Epoch: 66 cost= 6.026294250\n",
      "Valid error 6.035699\n",
      "Epoch: 67 cost= 6.026294115\n",
      "Valid error 6.035616\n",
      "Epoch: 68 cost= 6.026293966\n",
      "Valid error 6.035625\n",
      "Epoch: 69 cost= 6.026293847\n",
      "Valid error 6.035598\n",
      "Epoch: 70 cost= 6.026293707\n",
      "Valid error 6.035599\n",
      "Epoch: 70 total_batch: 39901\n",
      "Epoch: 71 cost= 6.026293554\n",
      "Valid error 6.035634\n",
      "Epoch: 72 cost= 6.026293408\n",
      "Valid error 6.035617\n",
      "Epoch: 73 cost= 6.026293256\n",
      "Valid error 6.035610\n",
      "Epoch: 74 cost= 6.026293126\n",
      "Valid error 6.035678\n",
      "Epoch: 75 cost= 6.026292983\n",
      "Valid error 6.035282\n",
      "Epoch: 76 cost= 6.026292842\n",
      "Valid error 6.035283\n",
      "Epoch: 77 cost= 6.026292697\n",
      "Valid error 6.035173\n",
      "Epoch: 78 cost= 6.026292577\n",
      "Valid error 6.035073\n",
      "Epoch: 79 cost= 6.026292427\n",
      "Valid error 6.035099\n",
      "Epoch: 80 cost= 6.026292298\n",
      "Valid error 6.034993\n",
      "Epoch: 80 total_batch: 39901\n",
      "Epoch: 81 cost= 6.026292146\n",
      "Valid error 6.034987\n",
      "Epoch: 82 cost= 6.026292009\n",
      "Valid error 6.034993\n",
      "Epoch: 83 cost= 6.026291869\n",
      "Valid error 6.034781\n",
      "Epoch: 84 cost= 6.026291719\n",
      "Valid error 6.034772\n",
      "Epoch: 85 cost= 6.026291588\n",
      "Valid error 6.034760\n",
      "Epoch: 86 cost= 6.026291454\n",
      "Valid error 6.034684\n",
      "Epoch: 87 cost= 6.026291308\n",
      "Valid error 6.034719\n",
      "Epoch: 88 cost= 6.026291167\n",
      "Valid error 6.034728\n",
      "Epoch: 89 cost= 6.026291020\n",
      "Valid error 6.034731\n",
      "Epoch: 90 cost= 6.026290881\n",
      "Valid error 6.034818\n",
      "Epoch: 90 total_batch: 39901\n",
      "Epoch: 91 cost= 6.026290746\n",
      "Valid error 6.034816\n",
      "Epoch: 92 cost= 6.026290607\n",
      "Valid error 6.034889\n",
      "Epoch: 93 cost= 6.026290447\n",
      "Valid error 6.034884\n",
      "Epoch: 94 cost= 6.026290315\n",
      "Valid error 6.034888\n",
      "Epoch: 95 cost= 6.026290172\n",
      "Valid error 6.034902\n",
      "Epoch: 96 cost= 6.026290049\n",
      "Valid error 6.034945\n",
      "Epoch: 97 cost= 6.026289921\n",
      "Valid error 6.034984\n",
      "Epoch: 98 cost= 6.026289768\n",
      "Valid error 6.035262\n",
      "Epoch: 99 cost= 6.026289631\n",
      "Valid error 6.035293\n",
      "Epoch: 100 cost= 6.026289491\n",
      "Valid error 6.035114\n",
      "Epoch: 100 total_batch: 39901\n",
      "Epoch: 101 cost= 6.026289355\n",
      "Valid error 6.035054\n",
      "Epoch: 102 cost= 6.026289213\n",
      "Valid error 6.035099\n",
      "Epoch: 103 cost= 6.026289075\n",
      "Valid error 6.035079\n",
      "Epoch: 104 cost= 6.026288942\n",
      "Valid error 6.035153\n",
      "Epoch: 105 cost= 6.026288788\n",
      "Valid error 6.034566\n",
      "Epoch: 106 cost= 6.026288650\n",
      "Valid error 6.034541\n",
      "Epoch: 107 cost= 6.026288508\n",
      "Valid error 6.034510\n",
      "Epoch: 108 cost= 6.026288384\n",
      "Valid error 6.034239\n",
      "Epoch: 109 cost= 6.026288232\n",
      "Valid error 6.034190\n",
      "Epoch: 110 cost= 6.026288114\n",
      "Valid error 6.034197\n",
      "Epoch: 110 total_batch: 39901\n",
      "Epoch: 111 cost= 6.026287972\n",
      "Valid error 6.034178\n",
      "Epoch: 112 cost= 6.026287838\n",
      "Valid error 6.034176\n",
      "Epoch: 113 cost= 6.026287706\n",
      "Valid error 6.034167\n",
      "Epoch: 114 cost= 6.026287565\n",
      "Valid error 6.034263\n",
      "Epoch: 115 cost= 6.026287426\n",
      "Valid error 6.034136\n",
      "Epoch: 116 cost= 6.026287285\n",
      "Valid error 6.034104\n",
      "Epoch: 117 cost= 6.026287161\n",
      "Valid error 6.034180\n",
      "Epoch: 118 cost= 6.026287021\n",
      "Valid error 6.034310\n",
      "Epoch: 119 cost= 6.026286878\n",
      "Valid error 6.034024\n",
      "Epoch: 120 cost= 6.026286739\n",
      "Valid error 6.034030\n",
      "Epoch: 120 total_batch: 39901\n",
      "Epoch: 121 cost= 6.026286613\n",
      "Valid error 6.034023\n",
      "Epoch: 122 cost= 6.026286467\n",
      "Valid error 6.033968\n",
      "Epoch: 123 cost= 6.026286325\n",
      "Valid error 6.033997\n",
      "Epoch: 124 cost= 6.026286191\n",
      "Valid error 6.034006\n",
      "Epoch: 125 cost= 6.026286061\n",
      "Valid error 6.033991\n",
      "Epoch: 126 cost= 6.026285906\n",
      "Valid error 6.034086\n",
      "Epoch: 127 cost= 6.026285783\n",
      "Valid error 6.034017\n",
      "Epoch: 128 cost= 6.026285654\n",
      "Valid error 6.034009\n",
      "Epoch: 129 cost= 6.026285516\n",
      "Valid error 6.034008\n",
      "Epoch: 130 cost= 6.026285376\n",
      "Valid error 6.034007\n",
      "Epoch: 130 total_batch: 39901\n",
      "Epoch: 131 cost= 6.026285241\n",
      "Valid error 6.033892\n",
      "Epoch: 132 cost= 6.026285113\n",
      "Valid error 6.033900\n",
      "Epoch: 133 cost= 6.026284976\n",
      "Valid error 6.033902\n",
      "Epoch: 134 cost= 6.026284835\n",
      "Valid error 6.033903\n",
      "Epoch: 135 cost= 6.026284705\n",
      "Valid error 6.033902\n",
      "Epoch: 136 cost= 6.026284560\n",
      "Valid error 6.033920\n",
      "Epoch: 137 cost= 6.026284424\n",
      "Valid error 6.033988\n",
      "Epoch: 138 cost= 6.026284292\n",
      "Valid error 6.034059\n",
      "Epoch: 139 cost= 6.026284166\n",
      "Valid error 6.034028\n",
      "Epoch: 140 cost= 6.026284023\n",
      "Valid error 6.034415\n",
      "Epoch: 140 total_batch: 39901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141 cost= 6.026283880\n",
      "Valid error 6.034397\n",
      "Epoch: 142 cost= 6.026283750\n",
      "Valid error 6.034416\n",
      "Epoch: 143 cost= 6.026283614\n",
      "Valid error 6.034412\n",
      "Epoch: 144 cost= 6.026283477\n",
      "Valid error 6.034468\n",
      "Epoch: 145 cost= 6.026283342\n",
      "Valid error 6.034475\n",
      "Epoch: 146 cost= 6.026283221\n",
      "Valid error 6.034494\n",
      "Epoch: 147 cost= 6.026283093\n",
      "Valid error 6.034517\n",
      "Epoch: 148 cost= 6.026282952\n",
      "Valid error 6.034462\n",
      "Epoch: 149 cost= 6.026282812\n",
      "Valid error 6.034336\n",
      "Epoch: 150 cost= 6.026282688\n",
      "Valid error 6.034103\n",
      "Epoch: 150 total_batch: 39901\n",
      "Epoch: 151 cost= 6.026282540\n",
      "Valid error 6.034034\n",
      "Epoch: 152 cost= 6.026282399\n",
      "Valid error 6.034133\n",
      "Epoch: 153 cost= 6.026282276\n",
      "Valid error 6.034136\n",
      "Epoch: 154 cost= 6.026282130\n",
      "Valid error 6.034110\n",
      "Epoch: 155 cost= 6.026282002\n",
      "Valid error 6.034237\n",
      "Epoch: 156 cost= 6.026281864\n",
      "Valid error 6.034361\n",
      "Epoch: 157 cost= 6.026281739\n",
      "Valid error 6.034414\n",
      "Epoch: 158 cost= 6.026281599\n",
      "Valid error 6.034450\n",
      "Epoch: 159 cost= 6.026281467\n",
      "Valid error 6.034429\n",
      "Epoch: 160 cost= 6.026281320\n",
      "Valid error 6.034445\n",
      "Epoch: 160 total_batch: 39901\n",
      "Epoch: 161 cost= 6.026281202\n",
      "Valid error 6.034582\n",
      "Epoch: 162 cost= 6.026281069\n",
      "Valid error 6.034544\n",
      "Epoch: 163 cost= 6.026280930\n",
      "Valid error 6.034741\n",
      "Epoch: 164 cost= 6.026280798\n",
      "Valid error 6.034741\n",
      "Epoch: 165 cost= 6.026280664\n",
      "Valid error 6.034732\n",
      "Epoch: 166 cost= 6.026280543\n",
      "Valid error 6.034893\n",
      "Epoch: 167 cost= 6.026280398\n",
      "Valid error 6.034846\n",
      "Epoch: 168 cost= 6.026280255\n",
      "Valid error 6.034733\n",
      "Epoch: 169 cost= 6.026280132\n",
      "Valid error 6.034749\n",
      "Epoch: 170 cost= 6.026280010\n",
      "Valid error 6.034742\n",
      "Epoch: 170 total_batch: 39901\n",
      "Epoch: 171 cost= 6.026279869\n",
      "Valid error 6.034647\n",
      "Epoch: 172 cost= 6.026279740\n",
      "Valid error 6.034606\n",
      "Epoch: 173 cost= 6.026279595\n",
      "Valid error 6.034497\n",
      "Epoch: 174 cost= 6.026279474\n",
      "Valid error 6.034441\n",
      "Epoch: 175 cost= 6.026279325\n",
      "Valid error 6.034527\n",
      "Epoch: 176 cost= 6.026279191\n",
      "Valid error 6.034636\n",
      "Epoch: 177 cost= 6.026279071\n",
      "Valid error 6.034613\n",
      "Epoch: 178 cost= 6.026278944\n",
      "Valid error 6.034499\n",
      "Epoch: 179 cost= 6.026278822\n",
      "Valid error 6.034513\n",
      "Epoch: 180 cost= 6.026278691\n",
      "Valid error 6.034474\n",
      "Epoch: 180 total_batch: 39901\n",
      "Epoch: 181 cost= 6.026278556\n",
      "Valid error 6.034580\n",
      "Epoch: 182 cost= 6.026278425\n",
      "Valid error 6.034598\n",
      "Epoch: 183 cost= 6.026278286\n",
      "Valid error 6.034634\n",
      "Epoch: 184 cost= 6.026278154\n",
      "Valid error 6.034678\n",
      "Epoch: 185 cost= 6.026278022\n",
      "Valid error 6.034667\n",
      "Epoch: 186 cost= 6.026277896\n",
      "Valid error 6.034669\n",
      "Epoch: 187 cost= 6.026277759\n",
      "Valid error 6.034898\n",
      "Epoch: 188 cost= 6.026277616\n",
      "Valid error 6.034899\n",
      "Epoch: 189 cost= 6.026277490\n",
      "Valid error 6.034858\n",
      "Epoch: 190 cost= 6.026277356\n",
      "Valid error 6.034857\n",
      "Epoch: 190 total_batch: 39901\n",
      "Epoch: 191 cost= 6.026277229\n",
      "Valid error 6.034907\n",
      "Epoch: 192 cost= 6.026277114\n",
      "Valid error 6.034900\n",
      "Epoch: 193 cost= 6.026276976\n",
      "Valid error 6.034952\n",
      "Epoch: 194 cost= 6.026276854\n",
      "Valid error 6.034942\n",
      "Epoch: 195 cost= 6.026276714\n",
      "Valid error 6.034946\n",
      "Epoch: 196 cost= 6.026276591\n",
      "Valid error 6.034850\n",
      "Epoch: 197 cost= 6.026276461\n",
      "Valid error 6.034585\n",
      "Epoch: 198 cost= 6.026276320\n",
      "Valid error 6.034627\n",
      "Epoch: 199 cost= 6.026276189\n",
      "Valid error 6.034637\n",
      "Epoch: 200 cost= 6.026276051\n",
      "Valid error 6.034524\n",
      "Optimization Finished!\n",
      "Test error 6.056763649\n",
      "Best validation 6.033892155\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0517 Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Create model ...\n",
      "WARNING:tensorflow:From <ipython-input-9-6d654c4c7a27>:25: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-10-4bf71d49cf71>:30: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "Start training ...\n",
      "初始化tf變數...\n",
      "Start Training cycle...\n",
      "Epoch: 0 total_batch: 39901\n",
      "Epoch: 1 cost= 6.610542733\n",
      "Valid error 6.026864\n",
      "Epoch: 2 cost= 6.030115571\n",
      "Valid error 6.015620\n",
      "Epoch: 3 cost= 6.026309124\n",
      "Valid error 6.014278\n",
      "Epoch: 4 cost= 6.026033292\n",
      "Valid error 6.014497\n",
      "Epoch: 5 cost= 6.026003293\n",
      "Valid error 6.014764\n",
      "Epoch: 6 cost= 6.025998269\n",
      "Valid error 6.014877\n",
      "Epoch: 7 cost= 6.025997115\n",
      "Valid error 6.014790\n",
      "Optimization Finished!\n",
      "Test error 6.035558701\n",
      "Best validation 6.014278412\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練完後神經網路隱藏層的權重可以拿來當每個和弦的Embedding\n",
    "embeddings為lookup table,維度12X1024，12是訓練神經網路時先把每個和弦當作一個字並用12-vecotor來表徵，1024是隱藏層節點數 <br>\n",
    "例:C和弦onset的位置為[0, 4, 7] <br>\n",
    "則拿出lookup table位置為[0,4,7]的三個row\n",
    "然後把3個row加總起來變成一個1X1024維度的陣列當做C和弦的Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loads the embeddings variable from the tensorflow checkpoint\n",
    "def load_embeddings(checkpoint_path):\n",
    "    with tf.Session() as session:\n",
    "        if checkpoint_path:\n",
    "            saver = tf.train.import_meta_graph(checkpoint_path+'/linear_D1024.ckpt-2.meta')\n",
    "            saver.restore(session, tf.train.latest_checkpoint(checkpoint_path))\n",
    "          \n",
    "            return session.run('embedding:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save_models/linear/0517\\linear_D1024.ckpt-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349615</td>\n",
       "      <td>1.956460</td>\n",
       "      <td>-1.227351</td>\n",
       "      <td>-0.751444</td>\n",
       "      <td>0.465206</td>\n",
       "      <td>0.503762</td>\n",
       "      <td>1.794863</td>\n",
       "      <td>-0.719427</td>\n",
       "      <td>-1.237653</td>\n",
       "      <td>0.563687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644730</td>\n",
       "      <td>0.670384</td>\n",
       "      <td>-0.176548</td>\n",
       "      <td>-1.369358</td>\n",
       "      <td>-0.149511</td>\n",
       "      <td>-0.922704</td>\n",
       "      <td>-0.327705</td>\n",
       "      <td>-0.071303</td>\n",
       "      <td>0.402505</td>\n",
       "      <td>0.084036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.592848</td>\n",
       "      <td>-0.107120</td>\n",
       "      <td>0.714792</td>\n",
       "      <td>-0.465543</td>\n",
       "      <td>-1.195532</td>\n",
       "      <td>-0.762941</td>\n",
       "      <td>1.661106</td>\n",
       "      <td>-0.282388</td>\n",
       "      <td>0.420009</td>\n",
       "      <td>-0.326179</td>\n",
       "      <td>...</td>\n",
       "      <td>2.402115</td>\n",
       "      <td>0.381457</td>\n",
       "      <td>0.565326</td>\n",
       "      <td>-0.065036</td>\n",
       "      <td>0.502722</td>\n",
       "      <td>-0.627436</td>\n",
       "      <td>1.225749</td>\n",
       "      <td>-1.161619</td>\n",
       "      <td>-1.473216</td>\n",
       "      <td>1.890960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065874</td>\n",
       "      <td>1.806204</td>\n",
       "      <td>0.977147</td>\n",
       "      <td>0.948749</td>\n",
       "      <td>1.384241</td>\n",
       "      <td>-0.563102</td>\n",
       "      <td>0.330593</td>\n",
       "      <td>0.987452</td>\n",
       "      <td>1.561236</td>\n",
       "      <td>-0.430407</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.476789</td>\n",
       "      <td>-1.020271</td>\n",
       "      <td>-0.295438</td>\n",
       "      <td>-0.732292</td>\n",
       "      <td>-0.222126</td>\n",
       "      <td>-0.176328</td>\n",
       "      <td>-0.535357</td>\n",
       "      <td>-1.580981</td>\n",
       "      <td>-1.248078</td>\n",
       "      <td>1.481397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.147361</td>\n",
       "      <td>-1.270813</td>\n",
       "      <td>-0.686739</td>\n",
       "      <td>-0.497780</td>\n",
       "      <td>-0.858078</td>\n",
       "      <td>-0.146922</td>\n",
       "      <td>1.427179</td>\n",
       "      <td>-0.525656</td>\n",
       "      <td>-0.976343</td>\n",
       "      <td>-0.480282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645246</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>-1.019520</td>\n",
       "      <td>0.377069</td>\n",
       "      <td>1.213726</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>2.158754</td>\n",
       "      <td>0.699689</td>\n",
       "      <td>-1.012467</td>\n",
       "      <td>-1.547001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.425817</td>\n",
       "      <td>-0.034812</td>\n",
       "      <td>1.414810</td>\n",
       "      <td>-1.395781</td>\n",
       "      <td>-1.014016</td>\n",
       "      <td>-0.269192</td>\n",
       "      <td>0.458952</td>\n",
       "      <td>-0.190879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144063</td>\n",
       "      <td>-0.193296</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.102511</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>-0.352411</td>\n",
       "      <td>-1.764494</td>\n",
       "      <td>-1.942408</td>\n",
       "      <td>-0.229272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.349615  1.956460 -1.227351 -0.751444  0.465206  0.503762  1.794863   \n",
       "1 -0.592848 -0.107120  0.714792 -0.465543 -1.195532 -0.762941  1.661106   \n",
       "2  0.065874  1.806204  0.977147  0.948749  1.384241 -0.563102  0.330593   \n",
       "3  1.147361 -1.270813 -0.686739 -0.497780 -0.858078 -0.146922  1.427179   \n",
       "4  0.077982  0.811102  0.425817 -0.034812  1.414810 -1.395781 -1.014016   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0 -0.719427 -1.237653  0.563687    ...     0.644730  0.670384 -0.176548   \n",
       "1 -0.282388  0.420009 -0.326179    ...     2.402115  0.381457  0.565326   \n",
       "2  0.987452  1.561236 -0.430407    ...    -1.476789 -1.020271 -0.295438   \n",
       "3 -0.525656 -0.976343 -0.480282    ...     0.645246  0.482403 -1.019520   \n",
       "4 -0.269192  0.458952 -0.190879    ...    -0.144063 -0.193296  0.347956   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0 -1.369358 -0.149511 -0.922704 -0.327705 -0.071303  0.402505  0.084036  \n",
       "1 -0.065036  0.502722 -0.627436  1.225749 -1.161619 -1.473216  1.890960  \n",
       "2 -0.732292 -0.222126 -0.176328 -0.535357 -1.580981 -1.248078  1.481397  \n",
       "3  0.377069  1.213726  0.185791  2.158754  0.699689 -1.012467 -1.547001  \n",
       "4  0.102511  0.984227  0.050228 -0.352411 -1.764494 -1.942408 -0.229272  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('save_models/linear/0517')\n",
    "pd.DataFrame(embeddings_trained).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用pretained好的chord2vec表徵每首曲子的每個和弦\n",
    "C和弦是chord2vec lookup表的[0,4,7]rows的總和  <br>\n",
    "把每個和弦的vector總和算出來變成1X500並做出一張表，之後查這張表的和弦對應的row以找出一個和弦的vector總和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n",
    "chord_index={\n",
    "    'C:maj':  1,\n",
    "    'Db:maj': 2,\n",
    "    'Db:min': 3,\n",
    "    'D:maj':  4,\n",
    "    'Eb:maj': 5,\n",
    "    'Eb:min': 6,\n",
    "    'E:maj':  7,\n",
    "    'E:min':  8,\n",
    "    'F:maj':  9,\n",
    "    'F:min':  10,\n",
    "    'Gb:maj': 11,\n",
    "    'Gb:min': 12,\n",
    "    'G:maj':  13,\n",
    "    'G:min':  14,\n",
    "    'Ab:maj': 15,\n",
    "    'Ab:min': 16,\n",
    "    'A:maj':  17,\n",
    "    'A:min':  18,\n",
    "    'Bb:maj': 19,\n",
    "    'Bb:min': 20,\n",
    "    'B:maj':  21,\n",
    "    'B:min':  22    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566418</td>\n",
       "      <td>1.683812</td>\n",
       "      <td>0.20987</td>\n",
       "      <td>-2.502728</td>\n",
       "      <td>2.306996</td>\n",
       "      <td>-2.498727</td>\n",
       "      <td>2.758559</td>\n",
       "      <td>-1.180686</td>\n",
       "      <td>-0.693577</td>\n",
       "      <td>0.337182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330586</td>\n",
       "      <td>1.583621</td>\n",
       "      <td>0.363409</td>\n",
       "      <td>-1.390158</td>\n",
       "      <td>0.842196</td>\n",
       "      <td>-0.7342</td>\n",
       "      <td>-0.880237</td>\n",
       "      <td>-3.225111</td>\n",
       "      <td>-2.940939</td>\n",
       "      <td>-0.939547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1        2         3         4         5         6   \\\n",
       "0  0.566418  1.683812  0.20987 -2.502728  2.306996 -2.498727  2.758559   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0 -1.180686 -0.693577  0.337182    ...     0.330586  1.583621  0.363409   \n",
       "\n",
       "         93        94      95        96        97        98        99  \n",
       "0 -1.390158  0.842196 -0.7342 -0.880237 -3.225111 -2.940939 -0.939547  \n",
       "\n",
       "[1 rows x 100 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=chord_vector.get('C:maj')\n",
    "Cmaj_Embedding=embeddings_trained[index].sum(axis=0).reshape(1, 100)\n",
    "pd.DataFrame(Cmaj_Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save_models/linear/0517\\linear_D1024.ckpt-2\n"
     ]
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('./save_models/linear/0517')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Chord_embedding_sum_lookup=np.array([])\n",
    "Chord_embedding_sum_lookup=np.append(Chord_embedding_sum_lookup,np.zeros(100))\n",
    "for chord in chord_vector:\n",
    "    index=chord_vector.get(chord)\n",
    "    chord_Embedding_sum=embeddings_trained[index].sum(axis=0).reshape(1, 100)\n",
    "    Chord_embedding_sum_lookup=np.append(Chord_embedding_sum_lookup,chord_Embedding_sum)\n",
    "Chord_embedding_sum_lookup=Chord_embedding_sum_lookup.reshape(23,100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "out = open(\"../Question_Answering_Structure/Chord_embedding_data/0517/Chord_embedding_sum_lookup\",\"wb\")\n",
    "pickle.dump(Chord_embedding_sum_lookup, out)\n",
    "print('ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 208.666666,
   "position": {
    "height": "230px",
    "left": "743px",
    "right": "20px",
    "top": "-6px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
